### 过拟合、欠拟合及其解决方案

#### 1. 模型选择、过拟合和欠拟合

##### 1.1 训练误差和泛化误差

训练误差是指在训练集上的损失，后者指模型在任意一个测试样本上损失的期望，常通过测试数据集上的误差来近似。使用损失函数即可计算出相应的误差。

##### 1.2 模型选择

###### 1.2.1 验证数据集

严格意义上，测试集往往是在模型训练充分之后(超参数经过多次迭代后)只运行一次。所以在调整模型及模型超参数时，我们预留一部分训练集作为验证集，并将验证集的损失近似为泛化误差，以作为我们调整模型的依据

###### 1.2.2 $K$ 折交叉验证

由于验证集不参与模型训练，当训练数据不够用时，我们通常选择 $K$ 折交叉验证( $K$ -fold cross-validation)。其做法是：将原始训练集分成 $K$ 份不重合的子数据集，然后做 $K$ 次训练以及验证，每次使用一个子数据集验证模型，其余 $K-1$ 个子数据集来训练模型

##### 1.3 过拟合和欠拟合

- 欠拟合：模型无法得到较低的训练误差
- 过拟合：模型的训练误差远小于其在测试集上的误差

###### 1.3.1 模型复杂度

如何解释模型复杂度呢？

如何约束模型复杂度呢?

- $L_2$ 范数正则化

如何防止过拟合现象

- 丢弃法(Dropout法)、正则化
- 增加训练样本

如何防止欠拟合现象

- 训练样本不够
- 模型复杂度过低